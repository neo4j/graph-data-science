[[algorithms-ml-linkprediction]]
= Link Prediction
:entity: relationship
:result: relationships
:algorithm: Link Prediction


[abstract]
--
This section describes the Link Prediction Model in the Neo4j Graph Data Science library.
--


[[algorithms-ml-linkprediction-intro]]
== Introduction

Link prediction is a common machine learning task applied to graphs: training a model to learn, between pairs of nodes in a graph, where relationships should exist.
You can think of this as building a model to predict missing relationships in your dataset or relationships that are likely to form in the future.
Neo4j GDS trains supervised machine learning models based on the relationships and node properties in your graph to predict the existence - and probability - of relationships.

Link Prediction can be used favorably together with <<algorithms-ml-models-preprocessing, pre-processing algorithms>>.

The basic work flow of Link Prediction contains the following parts which are described below:

* <<algorithms-ml-train-test-splitting, Creating training and test graphs>>
* <<algorithms-ml-linkprediction-train, Training and Evaluating model candidates>>
* <<algorithms-link-prediction-mutate, Applying a model for prediction>>

[[algorithms-ml-linkprediction-train]]
=== Training, Model Selection and Evaluation

When building a model, it is possible to specify multiple model configurations and a model selection metric.
The train mode, `gds.alpha.ml.linkPrediction.train`, is responsible for training and evaluating the models, selecting the best model, and storing it in the model catalog.

The train mode takes as input two relationship types representing the training graph and test graph respectively.
The relationship types must have an integer property, with values being either `0` or `1`.
If the value is `0` the relationship represents a negative example, meaning a node pair which is not connected in the original graph.
If the value is `1` the relationship represents a positive example, meaning a relationship which does exist in the original graph.

To obtain the feature vector for an example, the algorithm first forms node feature vectors for the source and target nodes of the example in question.
This is done by concatenating the property values of the specified feature properties in order into a node feature vector.
Thereafter, the algorithm uses a _link feature combiner_ to combine the two node feature vectors into the feature vector for the training example.
There are three supported link feature combiners:

* `L2`
** which gives a feature vector as `[(s_0 - t_0)^2 , (s_1 - t_1)^2, ..., (s_d - t_d)^2]`, where `[s_i]` and `[t_i]` are the source and target node feature vectors.
* `HADAMARD`
** which gives a feature vector as `[s_0 * t_0, s_1 * t_1, ..., s_d * t_d]`.
* `COSINE`
** which gives a single scalar feature, using the the link:http://en.wikipedia.org/wiki/Cosine_similarity[Cosine similarity] of source and target node feature vectors.

The precise steps of the train mode are:

1. The relationships of the training graph are divided into a number of folds, consisting of a training part and a validation part.
2. Each model candidate is trained on each train part and evaluated on the respective validation part.
   The training process uses a logistic regression algorithm, and the evaluation uses the <<algorithms-ml-metrics, AUCPR metric>>.
3. The model with the highest average score according to the metric will win the training.
4. The winning model will then be re-trained on the whole training graph and evaluated on the training graph as well as on the test graph.
5. The winning model will be registered in the <<model-catalog-ops, Model Catalog>>.

Trained models may then be used to predict the probability of a relationship between two nodes.

[[algorithms-link-prediction-mutate]]
=== Applying a Link Prediction model

A previously trained model can be applied by invoking the `gds.alpha.ml.linkPrediction.predict.mutate` mode.
This will retrieve the model by name from the model catalog.
The model will thereby be used to predict the probability of relationships between all node pairs in the graph that are not connected.
There are two mandatory configuration parameters, which limit the size of the output:

* `topN` retains the most probable predictions.
* `threshold` retains predictions whose probability is above the threshold.


[[algorithms-ml-train-test-splitting]]
=== Train/Test Splitting

In order to train a Link Prediction model, one needs training and test graphs as described <<algorithms-ml-linkprediction-train, above>>.
The recommended way to obtain these is by using <<algorithms-split-relationships, `gds.alpha.ml.splitRelationships()`>> procedure, once to produce the test graph, and another time for the training graph.
By invoking this procedure the first time, one obtains two new relationship types that represent the test graph and a 'remaining' graph.
One can then, invoke the procedure again, on the just created 'remaining' graph, which then creates a training graph and an even smaller 'remaining' graph.
<<algorithms-ml-linkprediction-examples-train, Below>>, is an example usage of how the `splitRelationships` procedure can be used to prepare the required datasets for training.

The 'remaining' graph after the second split can optionally be used to create node embeddings without data leakage from test or validation sets.

Note that, after the first invocation, we cannot use the 'remaining' graph as the training graph, because it not guaranteed to have `0/1` value relationship labels nor negative link examples.

[[algorithms-ml-metrics]]
=== Metrics

The Link Prediction model in the Neo4j GDS library supports only the Area Under the Precision-Recall Curve metric, abbreviated as AUCPR.
In order to compute precision and recall we require a set of examples, each of which has a positive or negative target.
For each example we have also a predicted target.
Given the true and predicted targets, we can compute precision and recall (for reference, see f.e. https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)[Wikipedia]).

Then, to compute the AUCPR, we construct the precision-recall curve, as follows:

- Each predicted target is associated with a prediction strength, for example the predicted probability of a positive target.
  We sort the examples in descending order of prediction strength.
- For all prediction strengths that occur, we use that strength as a threshold and for all examples of that strength or higher predict that these examples have positive targets.
- We now compute precision `p` and recall `r` and consider the tuple `(r, p)` as a point on a curve, the precision-recall curve.
- Finally, the curve is linearly interpolated and the area is computed as a union of trapezoids with corners on the points.

The curve will have a shape that looks something like this:

image::misc/precision-recall-trapezoid.png[precision-recall curve with trapezoid,align="center"]

Note here the blue area which shows one trapezoid under the curve.

The area under the Precision-Recall curve can also be interpreted as an average precision where the average is over different classification thresholds.

==== Class imbalance

Most graphs have far more non-connected node pairs than connected ones (e.g. sparse graphs).
Thus, typically we have an issue with _class imbalance_.
There are multiple strategies to account for imbalanced data.
In our procedure, the AUCPR metric is used which is considered more suitable than the commonly used AUROC (Area Under the Receiver Operating Characteristic) metric for imbalanced data.
One must also specify the configuration parameter `classRatio` which determines the weighting of negative example (non-connected node pairs) to connected node pairs.
This means upweighting the false positives by this ratio when computing precision.

Setting `classRatio` to `1.0` is consistent with _traditional_ evaluation and is recommended for comparison with other models evaluated this way.

The evaluation is typically done on graphs created by the `splitRelationships` procedure, which produces a set with equal number of positive and negative examples.
To compensate for the under-sampling of negative examples, `classRatio` can be set to the _true_ class ratio.
The true class ratio is computed as `(q - r) / q`, where `q = n(n-1)/2` is the number of possible undirected relationships, and `r` is the number of actual undirected relationships.
Please note that the `relationshipCount` reported by the <<catalog-graph-list, catalog-graph-list>> procedure is the _directed_ count of relationships summed over all existing relationship types.
Thus, we recommend using Cypher to obtain `r` on the source Neo4j graph.
For example, this query will count the number of relationships of type `T` or `R`:

[source, cypher]
----
MATCH (a)-[rel:T | R]-(b)
WHERE a < b
RETURN count(rel) AS r
----

Using the true class ratio approximates an evaluation on a sample according to the true class distribution.
The reported metric (AUCPR) then better reflects the expected precision on unseen highly imbalanced data.
With this type of evaluation one has to adjust expectations as the metric value then becomes much smaller.

Note that the `classRatio` can be set arbitrarily, and will influence the reported AUCPR score.

[[algorithms-ml-linkprediction-syntax]]
== Syntax

include::../../shared/syntax-intro-named-graph.adoc[]

WARNING: The named graphs must be projected in the `UNDIRECTED` orientation for the Link Prediction model.

.Link Prediction syntax per mode
[.tabbed-example]
====

[.include-with-train]
======
.Run Link Prediction in train mode on a named graph:
[source]
----
CALL gds.alpha.ml.linkPrediction.train(
  graphName: String,
  configuration: Map
) YIELD
  trainMillis: Integer,
  modelInfo: Map,
  configuration: Map
----

include::../../common-configuration/common-parameters-named-graph.adoc[]

include::../../common-configuration/common-train-configuration-named-graph.adoc[]

include::specific-train-configuration.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name          | Type    | Description
| trainMillis   | Integer | Milliseconds used for training.
| modelInfo     | Map     | Information about the training and the winning model.
| configuration | Map     | Configuration used for the train procedure.
|===

The `modelInfo` can also be retrieved at a later time by using the <<catalog-model-list, Model List Procedure>>.
The `modelInfo` return field has the following algorithm-specific subfields:

[opts="header",cols="1,1,6"]
|===
| Name           | Type          | Description
| bestParameters | Map           | The model parameters which performed best on average on validation folds according to the primary metric.
| metrics        | Map           | Map from metric description to evaluated metrics for various models and subsets of the data, see below.
|===

The `metrics` map contains an entry for each metric description (currently only `AUCPR`) and the corresponding results for that metric.
Each such result map contains the keys `train`, `validation`, `outerTrain` and `test`.
The latter two correspond to numeric values for the evaluation of the best model on the test set and its complement -- the outer train set.
The `train` and `validation` results contain lists of results for all candidate models (i.e. `params`). Each such result is in turn also a map with keys `params`, `avg`, `min` and `max`.
These correspond to the hyper-parameters of the model candidate, and statistics for the result of that model over cross-validation folds.
The structure of `modelInfo` is:

[source]
----
{
    bestParameters: Map,     // one of the maps specified in `params`
    metrics: {
        AUCPR: {
            test: Float,
            outerTrain: Float,
            train: [{
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            {
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            ...              // more results per model candidate
            ],
            validation: [{
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            {
                avg: Float,
                max: Float,
                min: Float,
                params: Map
            },
            ...              // more results per model candidate
            ]
        }
    }
}
----
======


[.include-with-mutate]
======
.Run Link Prediction in mutate mode on a named graph:
[source]
----
CALL gds.alpha.ml.linkPrediction.predict.mutate(
  graphName: String,
  configuration: Map
)
YIELD
  createMillis: Integer,
  computeMillis: Integer,
  postProcessingMillis: Integer,
  mutateMillis: Integer,
  relationshipsWritten: Integer,
  configuration: Map
----

include::../../common-configuration/common-parameters-named-graph.adoc[]

include::../../common-configuration/common-mutate-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name                 | Type    | Description
| createMillis         | Integer | Milliseconds for creating the graph.
| computeMillis        | Integer | Milliseconds for running the algorithm.
| postProcessingMillis | Integer | Milliseconds for computing the global metrics.
| mutateMillis         | Integer | Milliseconds for adding properties to the in-memory graph.
| relationshipsWritten | Integer | Number of relationships created.
| configuration        | Map     | Configuration used for running the algorithm.
|===
======
====

[[algorithms-ml-linkprediction-examples]]
== Examples

:algorithm-name: {algorithm}
:graph-description: social network
:image-file: link-prediction.svg
include::../../shared/examples-intro.adoc[]

.The following Cypher statement will create the example graph in the Neo4j database:
[source, cypher, role=noplay setup-query]
----
CREATE
  (alice:Person {name: 'Alice', numberOfPosts: 38}),
  (michael:Person {name: 'Michael', numberOfPosts: 67}),
  (karin:Person {name: 'Karin', numberOfPosts: 30}),
  (chris:Person {name: 'Chris', numberOfPosts: 132}),
  (will:Person {name: 'Will', numberOfPosts: 6}),
  (mark:Person {name: 'Mark', numberOfPosts: 32}),
  (greg:Person {name: 'Greg', numberOfPosts: 29}),
  (veselin:Person {name: 'Veselin', numberOfPosts: 3}),

  (alice)-[:KNOWS]->(michael),
  (michael)-[:KNOWS]->(karin),
  (michael)-[:KNOWS]->(chris),
  (michael)-[:KNOWS]->(greg),
  (will)-[:KNOWS]->(michael),
  (will)-[:KNOWS]->(chris),
  (mark)-[:KNOWS]->(michael),
  (mark)-[:KNOWS]->(will),
  (greg)-[:KNOWS]->(chris),
  (veselin)-[:KNOWS]->(chris),
  (karin)-[:KNOWS]->(veselin),
  (chris)-[:KNOWS]->(karin);
----

With the graph in Neo4j we can now project it into the graph catalog to prepare it for algorithm execution.
We do this using a native projection targeting the `Person` nodes and the `KNOWS` relationships.
We will also project the `numberOfPosts` property, so we can use it as a model feature.
For the relationships we must use the `UNDIRECTED` orientation.
This is because the Link Prediction model is defined only for undirected graphs.

include::../../shared/examples-named-native-note.adoc[]

.The following statement will create a graph using a native projection and store it in the graph catalog under the name 'myGraph'.
[source, cypher, role=noplay graph-create-query]
----
CALL gds.graph.create(
  'myGraph',
  {
    Person: {
      properties: ['numberOfPosts']
    }
  },
  {
    KNOWS: {
      orientation: 'UNDIRECTED'
    }
  }
)
----

WARNING: The Link Prediction model requires the graph to be created using the `UNDIRECTED` orientation for relationships.

In the following examples we will demonstrate using the Link Prediction model on this graph.


[[algorithms-ml-linkprediction-examples-train]]
=== Train

First, we must do the test/train splits.
For this we will make use of the `gds.alpha.ml.splitRelationships` procedure.
We will do one split to generate the test graph.

[source, cypher, role=noplay example-query]
----
CALL gds.alpha.ml.splitRelationships.mutate('myGraph', {
  relationshipTypes: ['KNOWS'],
  remainingRelationshipType: 'KNOWS_REMAINING',
  holdoutRelationshipType: 'KNOWS_TESTGRAPH',
  holdoutFraction: 0.2,
  negativeSamplingRatio: 1.0
}) YIELD relationshipsWritten
----

.Results
[opts="header"]
|===
| relationshipsWritten
| 24
|===

We will create copied relationships for each existing relationship, into either the `KNOWS_REMAINING` or the `KNOWS_TESTGRAPH` relationship types.
All relationships in `KNOWS_TESTGRAPH` will have a `label` property.
Additionally, a number of non-existing relationships will be created into the `KNOWS_TESTGRAPH` relationship type to be used as negative examples, with a `label` of `0`.

Next, we will create the train graph.

[source, cypher, role=noplay example-query]
----
CALL gds.alpha.ml.splitRelationships.mutate('myGraph', {
  relationshipTypes: ['KNOWS_REMAINING'],
  remainingRelationshipType: 'KNOWS_IGNORED_FOR_TRAINING',
  holdoutRelationshipType: 'KNOWS_TRAINGRAPH',
  holdoutFraction: 0.2,
  negativeSamplingRatio: 1.0
}) YIELD relationshipsWritten
----

.Results
[opts="header"]
|===
| relationshipsWritten
| 20
|===

With both training and test graphs, we are ready to train models.
We will use 5 validation folds, meaning we will split the train graph into 5 pairs, using one part of each pair for training and one for validation.
We set the class ratio to 1.33, which is calculated as the number of non-existing relationships over the number of existing relationships.
In our graph we have 8 nodes, which gives us a maximum of `8 * 7 / 2 = 28` undirected relationships.
We have 12 actual relationships, giving us a class ratio of `(28 - 12) / 12 = 1.33`.

[[algorithms-ml-linkprediction-examples-train-query]]
.Train a Link Prediction model:
[source, cypher, role=noplay example-query]
----
CALL gds.alpha.ml.linkPrediction.train('myGraph', {
  trainRelationshipType: 'KNOWS_TRAINGRAPH',
  testRelationshipType: 'KNOWS_TESTGRAPH',
  modelName: 'lp-numberOfPosts-model',
  featureProperties: ['numberOfPosts'],
  validationFolds: 5,
  negativeClassWeight: 1.33,
  randomSeed: 2,
  params: [
    {penalty: 0.5, maxEpochs: 1000},
    {penalty: 1.0, maxEpochs: 1000},
    {penalty: 0.0, maxEpochs: 1000}
  ]
}) YIELD modelInfo
RETURN
  modelInfo.bestParameters AS winningModel,
  modelInfo.metrics.AUCPR.outerTrain AS trainGraphScore,
  modelInfo.metrics.AUCPR.test AS testGraphScore
----

.Results
[opts="header"]
|===
| winningModel                    | trainGraphScore    | testGraphScore
| {maxEpochs: 1000, penalty: 0.5} | 0.7145922746781116 | 0.3512042965360351
|===

Here we can observe that the model candidate with penalty 0.5 performed the best in the training phase, with a score of about 71% over the train graph.
On the test graph, the model scored much lower at about 35%.
This indicates that the model reacted fairly well to the train graph, but did not generalise very well to unseen data.
In order to achieve a higher test score, we may need to use better features, a larger graph, or different model configuration.


[[algorithms-ml-linkprediction-examples-mutate]]
=== Mutate

In this example we will show how to use a trained model to predict new relationships in your in-memory graph.
In order to do this, we must first have an already trained model registered in the Model Catalog.
We will use the model which we trained in the <<algorithms-ml-linkprediction-examples-train-query, train example>> which we gave the name `'lp-numberOfPosts-model'`.

We must also make sure that we do not include any of the relationships from the train or test graphs, which we do by specifying a relationship filter for the original relationship type `'KNOWS'`.

[source, cypher, role=noplay example-query]
----
CALL gds.alpha.ml.linkPrediction.predict.mutate('myGraph', {
  relationshipTypes: ['KNOWS'],
  modelName: 'lp-numberOfPosts-model',
  mutateRelationshipType: 'KNOWS_PREDICTED',
  topN: 5,
  threshold: 0.45
}) YIELD relationshipsWritten
----

.Results
[opts="header"]
|===
| relationshipsWritten
| 10
|===

We specified `threshold` to filter out predictions with probability less than 45%, and `topN` to further limit output to the top 5 relationships.
Because we are using the `UNDIRECTED` orientation, we will write twice as many relationships to the in-memory graph.

In order to analyze our predicted relationships we will write them back to Neo4j:

[source, cypher, role=noplay example-query]
----
CALL gds.graph.writeRelationship('myGraph', 'KNOWS_PREDICTED', 'probability')
YIELD relationshipsWritten, propertiesWritten
----

.Results
[opts="header"]
|===
| relationshipsWritten | propertiesWritten
| 10                   | 10
|===

The end result looks like this:

image::example-graphs/link-prediction-mutate.svg[align="center"]

In yellow we highlight the predicted relationships.
